{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b66a529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:05:48.785458Z",
     "start_time": "2024-03-26T18:05:48.780998Z"
    }
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# executed in 5ms, finished 20:05:48 2024-03-26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185589eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Course\n",
    "/\n",
    "Unit 3 Methods of Estimation\n",
    "/\n",
    "(Optional) Recitation. Distance measures between distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe7620",
   "metadata": {},
   "source": [
    "$\\quad$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f319d108",
   "metadata": {},
   "source": [
    "# Distances between probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31089c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:01:59.348514Z",
     "start_time": "2024-03-26T18:01:59.341472Z"
    }
   },
   "source": [
    "Расстояние между распределениеями вероятностей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d5b05",
   "metadata": {},
   "source": [
    "## Обзор TV и KL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e575ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:03:04.846554Z",
     "start_time": "2024-03-26T18:03:04.839402Z"
    }
   },
   "source": [
    "Сначало посмотрим как они выглядят."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce6a0d",
   "metadata": {},
   "source": [
    "### Нотация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058d344",
   "metadata": {},
   "source": [
    "$\\mathcal{P,Q,R}$ - это распределения вероятностей над одиним и тем же пространсвтом $E$.\n",
    "\n",
    "Мы ожидаем что у них есть **плотности** или **массы** pdf pmf. Для удобства назовем их $p,q,r$\n",
    "\n",
    "в этом примере мы будем использовать $p,q,r$ как для плотностей так и для масс."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52af75b",
   "metadata": {},
   "source": [
    "#### Что значит плотности?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bbc31c",
   "metadata": {},
   "source": [
    "_Subset - подмножество\\\n",
    "Sample slpace - Пространство элементарных событий_\n",
    "Распределение вероятностей\n",
    "\n",
    "что значит плотность?\n",
    "\n",
    "Помните, что означает наличие функции плотности? Это значит, что когда я даю вам подмножество пространства, это подмножество должно быть 'хорошо определённым'. Особенно это актуально, когда мы рассматриваем $E$ как множество действительных чисел. Существуют специфически созданные наборы, для которых нельзя корректно назначить вероятность. Но мы обычно не акцентируем на этом внимание и не слишком беспокоимся об этом. Большинство обычных множеств, которые вы можете придумать, не вызывают никаких проблем.\n",
    "\n",
    "Это значит что есть подмножество из пространства $A \\subseteq E$ и вероятность этого подмножество выражается как интеграл по $A$ плотности p(x)\n",
    "\n",
    "$$A \\subseteq E: \\mathcal{P}(A)=\\int_A \\mathcal{p}(x)dx\\left[=\\sum_{X\\in A}\\mathcal{p}(x)\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4239c4c",
   "metadata": {},
   "source": [
    "#### почему мы вообще паримся по поводу \"Расстояний между вероятностными мерами\" ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d36fda",
   "metadata": {},
   "source": [
    "большенство наших настроек в статистике выглядят так.\n",
    "\n",
    "$\\left(\\mathcal{P}_\\Theta\\right)$ - параметрическое семействой описанныое пераметром $\\theta$ из набора параметров $\\Theta$: \n",
    "\n",
    "$$\\left(\\mathcal{P}_\\Theta\\right)_{\\theta \\in \\Theta}$$\n",
    "\n",
    "то есть мы предполагаем что реальность аппроксимируется этим семейством. и параметро $\\theta$ несет какой-то важный смысл для нас. к примеру рос человека, время ожидания и т.п.\n",
    "\n",
    "_\n",
    "\n",
    "Так зачем нам волноваться о расстояниях между вероятностными мерами? Большинство наших задач в статистике выглядят следующим образом. У нас есть некоторое параметрическое семейство, заданное параметром $\\theta$ в множестве параметров $\\theta\\in\\Theta$. И теперь мы, по сути, предполагаем, что реальность может быть аппроксимирована этим семейством. И мы пытаемся оценить $\\theta$. Часто \n",
    "$\\theta$ имеет для нас какой-то смысл. Так что первый вопрос, который мы обычно задаём, или первый вопрос, который мы обычно хотим задать: **действительно ли $\\theta$ идентифицировано?** \\\n",
    "Это означает, если у меня есть два разных значения, $\\theta$ и $\\theta'$, приводят ли они действительно к разным распределениям? Потому что если нет, то у меня нет способа узнать их из того, что я наблюдаю из этого распределения. Это первый вопрос. И когда мы убедились, что действительно настроили модель так, что $\\theta$ идентифицировано, тогда мы можем спросить, насколько хорошо $\\theta$ идентифицировано?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b85ad8",
   "metadata": {},
   "source": [
    "##### Первый вопрос - А можно вообще определить значение $\\theta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1149aa34",
   "metadata": {},
   "source": [
    "К примеру у нас есть два разных значения $\\theta$ и $\\theta'$, а они будут приводить нас к разным распределениям? Потому что если - нет то как мы можем найти нужно значние вообще?\n",
    "\n",
    "Допустим мы убедили себя что у нас определна модель, и параметр можно установить, то мы задаем след. вопрос:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8117a56d",
   "metadata": {},
   "source": [
    "##### Второй вопрос - Как хорошо определен параметр $\\theta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36f6290",
   "metadata": {},
   "source": [
    "Или - если у нас есть функция дле измерения расстояние между двумя мерами вероятности, то мы можем задаться вопросом поиска значения расстояния между $\\mathcal{P}_\\theta$ и $\\mathcal{P}_{\\theta'}$\n",
    "$$\\left(\\mathcal{P}_\\Theta\\right)_{\\theta \\in \\Theta}\\, \\mathcal{Q}:d(\\mathcal{P}_\\theta,\\mathcal{P}_{\\theta'})=?$$\n",
    "\n",
    "Если $\\theta$ и ${\\theta'}$ далеко друг от друга, то может быть и $\\mathcal{P}_\\theta$ и $\\mathcal{P}_{\\theta'}$ тоже далеко друг от друга? Можно ли собрать достаточно информации из распределений, чтобы отличить параметры друг от друга?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4d15c",
   "metadata": {},
   "source": [
    "#### Estimator / Оценщик"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e58d0",
   "metadata": {},
   "source": [
    "Когда мы работаем с анализом данных, одной из ключевых задач является сравнение распределений данных, которые мы наблюдаем, с теоретическими распределениями, представляющими различные модели. Чтобы понять, какое из теоретических распределений лучше всего соответствует нашим данным, нам нужен специальный метод оценки. Этот метод включает в себя определение параметра $\\theta$, который помогает нам количественно оценить 'близость' или 'сходство' между наблюдаемым распределением и каждым из потенциальных теоретических распределений.\n",
    "\n",
    "Один из таких методов — это метод максимального правдоподобия (MLE). MLE позволяет нам найти наиболее вероятное значение параметра \n",
    "$\\theta$, делая теоретическое распределение как можно более похожим на распределение, которое мы видим в наших данных. Иными словами, мы используем MLE для 'настройки' параметров нашей модели так, чтобы она наилучшим образом описывала наблюдаемые данные.\n",
    "\n",
    "Это подход, который делает акцент не просто на сравнении чисел или формул, а на понимании, как изменение параметров модели влияет на её способность точно отражать реальность данных. Таким образом, выбор наилучшего теоретического распределения и соответствующих параметров становится важным шагом в анализе и понимании данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f0294",
   "metadata": {},
   "source": [
    "### Меры расстояний"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a8d47",
   "metadata": {},
   "source": [
    "#### Total Variation Distribution (TV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d4194",
   "metadata": {},
   "source": [
    "$$\\text{TV}(\\mathcal{P}, \\mathcal{Q})=\\sup_{A\\subseteq E}|\\mathcal{P}-\\mathcal{Q}|\n",
    "=\\frac{1}{2}\\int_E |p(x)-q(x)|dx$$\n",
    "\n",
    "По факту это $L_1$ расстояния между двумя функциями\n",
    "\n",
    "Для дискретных наблюдений\n",
    "$$\\left[=\\frac{1}{2}\\sum_{x\\in E}|p(x)-q(x)|\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf71abba",
   "metadata": {},
   "source": [
    "#### Kullback-Leibler divergence (KL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ceb82",
   "metadata": {},
   "source": [
    "$$\\text{KL}(\\mathcal{P}, \\mathcal{Q})=\\text{KL}(\\mathcal{P}\\|\\mathcal{Q})$$\n",
    "мы называем это Дивергенцией а не Расстоянием потому что оно не **симметрично**. тоемть мы не может pq поменять местами и получить тоже самое значение\n",
    "\n",
    "Для непрерывных \n",
    "$$\\int_{x\\in E}p(x)\\log(\\frac{p(x)}{q(x)})dx, q(x)=0\\Rightarrow p(x)=0$$ это есть ожидание от логарифма. потому что умножаем pdf на логарифм\n",
    "\n",
    "а что елси q = 0  - то получатся что мы хотим такое избежать. тоесть мы хотим чтобы p тоже было  0 . тогда получитсья что вероятность такого равно нулю. что значить что этого просто не было/не возможно. Если pdf p стремиться к нулю то и логарифм будет стремиться к нулю. \n",
    "\n",
    "Но если q пойдет к нулю, то это будет проблема, потому что появиться бесконечность в этом случае KL$\\infty,\\, \\exists x: q(x)=0, p(x)=0 $\n",
    "\n",
    "\n",
    "Для дискреттных случаев\n",
    "$$\\sum_{x \\in E} p(x)\\log(\\frac{p(x)}{q(x)}) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c03166d",
   "metadata": {},
   "source": [
    "# Примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb434b6",
   "metadata": {},
   "source": [
    "## Convergence of Poisson distributions to the delta function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fc1091",
   "metadata": {},
   "source": [
    "первая плотность $\\mathcal{P}_n=\\text{Poi}(\\frac{1}{n})$\n",
    "\n",
    "вторая будет странная - все ее масса будет у одной точке.\n",
    "$\\mathcal(Q)=\\delta_0$\n",
    "\n",
    "Задача:\n",
    "показать что $$\\text{TV}(\\mathcal{P}_n, \\mathcal{Q}) \\xrightarrow [n \\to \\infty ]{} 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a0b55",
   "metadata": {},
   "source": [
    "$\\left[\\text{Poi}(\\lambda) \\, \\text{has pmf} \\,\n",
    "p_{\\lambda}(k)=\\frac{\\lambda^k}{k!}e^{-\\lambda}, k=0,1,2...;\\,\\,q(k)=\\begin{cases}\n",
    "    1, \\,  \\, k= 1 \\\\\n",
    "    0,\\,\\, \\text{otherwise}\n",
    "\\end{cases}\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e45e9",
   "metadata": {},
   "source": [
    "как мы это докажем? мы будем использовать определение KL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0263b69",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\text{TV}(\\mathcal{P}_n, \\mathcal{Q}) &=\\frac{1}{2}\\sum_{k=0}^{\\infty}|p_{1/2}(k)-q(k)|\\\\\n",
    "&=\\frac{1}{2}\\sum_{k=0}^{\\infty}|p_{1/2}(k)-q(k)|\\\\\n",
    "&=\\frac{1}{2}\\sum_{k=0}^{\\infty}|\\frac{\\lambda^k}{k!}e^{-\\lambda}-\\delta_0(k)|\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "Так как по факту $\\delta_0(k)$ будет давать 1 только в случае когда $k=0$, то мы может его вынести отдельно и разделить выражение.\n",
    "\n",
    "$$=\n",
    "\\frac{1}{2}\n",
    "    \\left|\\frac{\\frac{1}{n}^0}{0!}e^{-\\frac{1}{n}}-1\\right|+\n",
    "\\frac{1}{2}\n",
    "    \\sum_{k\\ge1}^{\\infty}\n",
    "        \\left|\\frac{\\frac{1}{n}^k}{k!}e^{-\\frac{1}{n}}\\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcebd2a",
   "metadata": {},
   "source": [
    "для первого выражение суммы, мы знаем что $\\frac{1}{n}^0=1$, а также по определению интегралов $0!=1$. у нас останется $e^{-\\frac{1}{n}}$. мы знаем что exponent непрерывная при том что $n \\to \\infty$ $\\frac{1}{n}\\to0$, а соотв $e^0=1$\\\n",
    "\n",
    "Получается что все первое выражение стремитсья к нулю\n",
    "$\\frac{1}{2}\n",
    "    \\left|\\frac{\\frac{1}{n}^0}{0!}e^{-\\frac{1}{n}}-1\\right|\\to0\n",
    "$\n",
    "\n",
    "Второе выражение более хитрое, и его нужно решать осторожно, потому что мы имеем дело с серией, поэтому сказав что чать внутри модуля стремиться к нулю, не будет достаточно сказать что вся серия стремится к нулю. Но может применить трюк.\n",
    "\n",
    "Мы можем избавиться от модуля, потому что все значение внутри положительные числа.\n",
    "$\\frac{1}{2}\n",
    "    \\sum_{k\\ge1}^{\\infty}\n",
    "        \\frac{\\frac{1}{n}^k}{k!}e^{-\\frac{1}{n}}$\n",
    "\n",
    "\n",
    "Тогда мы может рассмотреть сумму (без 1/2) как ни что иное как \"вероятность Poisson для последовательности \n",
    "$$\\mathcal{P}_n(\\{1,2,\\dots\\})$$\n",
    "это выражение есть комплимент для $\\mathcal{P}_n(\\{0\\})$, и мы может отнять от 1 это компремени.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{P}_n(\\{1,2,\\dots\\})&=1-\\mathcal{P}_n(\\{0\\})\\\\\n",
    "&=1-\\frac{\\frac{1}{n}^0}{0!}e^{-\\dfrac{1}{n}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "и мы уже видели это выражение и оно стремиться к нулю\n",
    "\n",
    "$$=1-\\tfrac{\\tfrac{1}{n}^0}{0!}e^{-\\dfrac{1}{n}}\\xrightarrow [n \\to \\infty ]{} 0$$\n",
    "\n",
    "итого мы доказали что требовалось."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a904c95",
   "metadata": {},
   "source": [
    "##  KL between binomial distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47452dda",
   "metadata": {},
   "source": [
    "Рассмотрим для дискретных распределений\n",
    " $\\mathcal{P}_n=\\text{Bin}(n,p), \\, \\mathcal{Q}_n=\\text{Bin}(n,p), \\, p,q\\in(0,1)$\n",
    " \n",
    "Напомним себе что $Bin$ это монетка которая может приземлиться на одну из сторон с вероятностью $p$ и мы ее подрасываем $n$ независемых раз, и смотрим сколько раз выпала решка (1)\n",
    "\n",
    "$f(p,k)=C_n^k p^k(1-p)^{n-k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b20e9",
   "metadata": {},
   "source": [
    "Вспомним как выглядит KL\n",
    "$$\\text{KL}(\\mathcal{P}\\|\\mathcal{Q})=\\sum_{x \\in E} f(p,k)\\log(\\frac{f(p,k)}{f(q,k)}) $$\n",
    "Рассмотрим все то что происходит внутри логарифма. напомним себе что KL это ожидание от логарифма.\n",
    "Подставим pdf в логарифм\n",
    "\n",
    "$$=\\sum_{x \\in E} f(p,k)\\log\\left[\\frac{C_n^k p^k(1-p)^{n-k}}{C_n^k q^k(1-q)^{n-k}}\\right]$$\n",
    "\n",
    "Сразу заметим что $C_n^k$ сокращается.\n",
    "оставшиеся элементы разделим на две дроби\n",
    "\n",
    "$$\\log\\left[\\frac{p^k}{q^k}\\frac{(1-p)^{n-k}}{(1-q)^{n-k}}\\right]$$\n",
    "\n",
    "и воспользуемся правилом логарифма, превратив выражение в сумму логарифмов\n",
    "\n",
    "$$=\\sum_{x \\in E}f(p,k)\n",
    "    \\left[\n",
    "        \\log\\left((\\frac{p}{q})^k\\right) + \n",
    "        \\log\\left((\\frac{1-p}{1-q})^{n-k}\\right)\n",
    "      \\right]$$\n",
    "упростим выражние, вынесем степени внутри логарифма, перед логарифмом\n",
    "\n",
    "$$=\\sum_{x \\in E}f(p,k)\n",
    "    \\left[\n",
    "        k\\log\\left(\\frac{p}{q}\\right) + \n",
    "        (n-k)\\log\\left(\\frac{1-p}{1-q}\\right)\n",
    "      \\right]$$\n",
    "если внимательно посмотреть на логарифма, то это просто константы, и они не зависят от $k$ и их можно вынести\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&=\\sum_{x \\in E}\n",
    "    \\left[\n",
    "        f(p,k)k\\log\\left(\\frac{p}{q}\\right) + \n",
    "        f(p,k)(n-k)\\log\\left(\\frac{1-p}{1-q}\\right)\n",
    "      \\right]\\\\\n",
    "&=\\sum_{x \\in E}\n",
    "    \\left[\n",
    "        f(p,k)k\\log\\left(\\frac{p}{q}\\right)\\right] + \n",
    "   \\sum_{x \\in E}\\left[\n",
    "        f(p,k)(n-k)\\log\\left(\\frac{1-p}{1-q}\\right)\n",
    "      \\right]\\\\\n",
    "&=\\log\\left(\\frac{p}{q}\\right)\\sum_{x \\in E}\n",
    "    \\left[\n",
    "        f(p,k)k\\right] + \n",
    "   \\log\\left(\\frac{1-p}{1-q}\\right)\\sum_{x \\in E}\\left[\n",
    "        f(p,k)(n-k)\n",
    "      \\right]\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fd4510",
   "metadata": {},
   "source": [
    "$\\sum_{x \\in E}f(p,k)k$ ожидание для $k$ есть ни что иное как PMF\n",
    "Если $X\\sim\\text{Bin}(n,p)$ тогда ожидание  $\\mathbb{E}[X]=n\\cdot p$. тогда у нас получается что \n",
    "$$=\\log\\frac{p}{q}np+\\log(\\frac{1-p}{1-q})(n-np)$$\n",
    "Мы закончили"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f8b1b1",
   "metadata": {},
   "source": [
    "Подметим что если позволить $q\\to 0$\n",
    "\n",
    "$np$ и $(n-np)$ не маняются. \n",
    "\n",
    "$q\\to0, \\frac{p}{q}\\to\\infty, \\log\\frac{p}{q}\\to\\infty$\n",
    "\n",
    "\n",
    "$1-q\\to1, \\log(\\frac{1-p}{1-q})\\to \\text{finite number}$\n",
    "\n",
    "итого $\\text{KL}\\to \\infty$ оно стремиться к бесконечности, и станет бесконечным если $q=0$\n",
    "$q=0, p\\in (0,1): \\text{KL}(\\mathcal{P}\\|\\mathcal{Q})=\\infty$ такое может случаться в KL divergence.\n",
    "\n",
    "В части лагарифма $\\log(\\frac{f(p,k)}{f(q,k)})$ если часть $f(q,k)$ \"исчезает\" а $f(p,k)$ \"остается\", тогда начем \"компенсировать\" исчезновение делителя, тогда KL равно бесконечности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa23aa0",
   "metadata": {},
   "source": [
    "## KL between Gaussian distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd3a6dd",
   "metadata": {},
   "source": [
    "Рассмотрим для непрерывных распределений\n",
    " $\\mathcal{P}_n=\\mathcal{N}(a,1), \\, \\mathcal{Q}_n=\\mathcal{N}(b,1), \\, p,q\\in \\mathbb{R}, \\, f_{a,\\sigma^2}(x)=\\dfrac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\dfrac{1}{2\\sigma^2}(x-a)^2}$\n",
    "Вспомним формулу KL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07e6306",
   "metadata": {},
   "source": [
    "$$\\text{KL}(\\mathcal{P}\\|\\mathcal{Q})=\\int_{\\mathbb{R}} f_{a,1}(x)log\\left[\\frac{f_{a,1}(x)}{f_{b,1}(x)}\\right]dx $$\n",
    "\n",
    "подставим наши плотности, учтем что $\\sigma^2=1$\n",
    "\n",
    "$$=\\int_{\\mathbb{R}} f_{a,1}(x)\\log\\left[\\frac{\\dfrac{1}{\\sqrt{2\\pi}} e^{-\\dfrac{1}{2}(x-a)^2}}{\\dfrac{1}{\\sqrt{2\\pi}} e^{-\\dfrac{1}{2}(x-b)^2}}\\right]dx $$\n",
    "\n",
    "Мы видим что $\\dfrac{1}{\\sqrt{2\\pi}}$ сокращаются\n",
    "\n",
    "используем правило степеней для $\\dfrac{e^a}{e^b}=e^{a-b}$\n",
    "\n",
    "\n",
    "$$\n",
    "=\\int_{\\mathbb{R}} f_{a,1}(x)\n",
    "    \\log\n",
    "        e^{\n",
    "            -\\frac{1}{2}(x-a)^2-(-\\frac{1}{2}(x-b)^2)}\n",
    "        dx\\\\\n",
    "=\\int_{\\mathbb{R}} f_{a,1}(x)\n",
    "    \\log\n",
    "        e^{\n",
    "            -\\frac{1}{2}(x-a)^2+\\frac{1}{2}(x-b)^2}\n",
    "        dx$$\n",
    "Упростим степень $e$\n",
    "\n",
    "$=-\\frac{1}{2}(x-a)^2+\\frac{1}{2}(x-b)^2$\\\n",
    "$=-\\frac{1}{2}(x^2-2xa+a^2)+-\\frac{1}{2}(x^2-2xb+b^2)$\\\n",
    "$=-\\frac{1}{2}x^2+\\frac{2}{2}xa-\\frac{1}{2}a^2+\\frac{1}{2}x^2-\\frac{2}{2}xb-\\frac{1}{2}b^2$\\\n",
    "$=xa-xb-\\frac{1}{2}a^2+\\frac{1}{2}b^2$\\\n",
    "$=x(a-b)-\\frac{1}{2}(a^2-b^2)$\n",
    "\n",
    "сократим логарифм e\n",
    "$$\n",
    "=\\int_{\\mathbb{R}} f_{a,1}(x)\n",
    "    \\left[x(a-b)-\\frac{1}{2}a^2+\\frac{1}{2}b^2\\right]\n",
    "        dx$$\n",
    "        \n",
    "$$=(a-b)\\int_{\\mathbb{R}} xf_{a,1}(x)dx-(\\frac{1}{2}a^2+\\frac{1}{2}b^2)\\int_{\\mathbb{R}} f_{a,1}(x)dx$$\n",
    "\n",
    "мы знаем что первый интеграл это просто Ожидание от первой перменной\\\n",
    "а второй интеграл, просто сумма всех вероятностей для нее же.\n",
    "\\\n",
    "$\\int_{\\mathbb{R}} xf_{a,1}(x)dx=a$\\\n",
    "$\\int_{\\mathbb{R}} f_{a,1}(x)dx=1$\n",
    "\n",
    "$$=\\left[(a-b)a\\right] - \\left[\\frac{1}{2}a^2+\\frac{1}{2}b^2\\right]\\\\\n",
    "=\\dfrac{1}{2}(a-b)^2$$\n",
    "\n",
    "итого\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487a7eb",
   "metadata": {},
   "source": [
    "получается что это квадрат разници средних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cecf44c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:42:22.711172Z",
     "start_time": "2024-03-26T23:42:22.706512Z"
    }
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80604780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:42:41.554651Z",
     "start_time": "2024-03-26T23:42:41.549944Z"
    }
   },
   "outputs": [],
   "source": [
    "# executed in 5ms, finished 01:42:22 2024-03-27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3863e364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
